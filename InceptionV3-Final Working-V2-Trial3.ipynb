{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import backend as K\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn.metrics as metrics \n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "# build the VGG16 network\n",
    "base_model = applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, \n",
    "                                input_shape=(150,150,3))\n",
    "print('Model loaded.')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the model we will train\n",
    "model =Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of trainable weights before freezing: ', len(model.trainable_weights))\n",
    "## to freesze all convolutional layers in pretrained network method 1\n",
    "# base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred,0,1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true,0,1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "# def precision_m(y_true, ypred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred,0,1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred,0,1)))\n",
    "#     precision = true_positives/(predicted_positives+K.epsilon())\n",
    "#     return precision \n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional pretrained layers method 2\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "print('After freezing: ', len(model.trainable_weights))\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-4),metrics=['acc'], loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/home/mlab/Documents/brats_hl_data/train'\n",
    "validation_data_dir = '/home/mlab/Documents/brats_hl_data/val'\n",
    "# 44938\n",
    "# 5616\n",
    "nb_train_samples = 44938\n",
    "nb_validation_samples = 5616\n",
    "epochs = 16\n",
    "batch_size = 128\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes = train_generator.classes\n",
    "print(true_classes)\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "history =model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=nb_train_samples//batch_size,\n",
    "                             epochs=epochs,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes_1 = validation_generator.classes\n",
    "print(true_classes)\n",
    "class_labels_1 = list(validation_generator.class_indices.keys())\n",
    "print(class_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = (Y_pred<0.475).astype(np.int)\n",
    "\n",
    "# print('Confusion Matrix')\n",
    "# print(confusion_matrix(true_classes_1, y_pred))\n",
    "# print('Classification Report')\n",
    "# print(classification_report(validation_generator.classes, y_pred, \n",
    "#                             target_names=class_labels_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(validation_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(true_classes_1,y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report= sklearn.metrics.classification_report(true_classes_1, y_pred, \n",
    "                                              target_names = class_labels_1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(validation_generator.classes, y_pred)\n",
    "\n",
    "# create plot\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
    "_ = plt.xlabel('False Positive Rate')\n",
    "_ = plt.ylabel('True Positive Rate')\n",
    "_ = plt.title('ROC Curve')\n",
    "_ = plt.xlim([-0.02, 1])\n",
    "_ = plt.ylim([0, 1.02])\n",
    "_ = plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(validation_generator.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchX, batchy = train_generator.next()\n",
    "_, accuracy = model.evaluate(batchX, batchy)\n",
    "print('Accuracy training: %.2f' % (accuracy*100))\n",
    "batchXv, batchyv = validation_generator.next()\n",
    "_, accuracy = model.evaluate(batchXv, batchyv)\n",
    "print('Accuracy val: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the train and val curve\n",
    "#get the details from the history object\n",
    "acc = history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "#train and validation accuracy\n",
    "plt.plot(epochs,acc,'b',label='Training accuracy')\n",
    "plt.plot(epochs,val_acc,'r',label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validation loss\n",
    "plt.plot(epochs, loss, 'b',label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r',label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory('/home/mlab/Documents/brats_hl_data/test', \n",
    "                                      class_mode='binary', \n",
    "                                      batch_size=batch_size, \n",
    "                                      target_size=(150,150))\n",
    "scores = model.evaluate_generator(test_generator, steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "# Y_pred = model.predict_generator(val_generator, 5616 // batch_size)\n",
    "nb_test_samples=5619\n",
    "Y_pred1 = model.predict_generator(test_generator,nb_test_samples//batch_size+1)\n",
    "# y_pred = np.argmax(Y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes_2 = test_generator.classes\n",
    "print(true_classes_2)\n",
    "class_labels_2 = list(test_generator.class_indices.keys())\n",
    "print(class_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred1 = (Y_pred1<0.5).astype(np.int)\n",
    "y_pred1 = (Y_pred1 < 0.475).astype(np.int)\n",
    "# print(y_pred)\n",
    "# print('Confusion Matrix')\n",
    "# print(confusion_matrix(true_classes_2, y_pred1))\n",
    "# print('Classification Report')\n",
    "# print(classification_report(true_classes_2, y_pred1, target_names=class_labels_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix1 = metrics.confusion_matrix(true_classes_2,y_pred1)\n",
    "print(confusion_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report1= sklearn.metrics.classification_report(true_classes_2, y_pred1, \n",
    "                                               target_names = class_labels_2)\n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Loss: \", scores[0],\"\\n\",\"Accuracy: \", scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
