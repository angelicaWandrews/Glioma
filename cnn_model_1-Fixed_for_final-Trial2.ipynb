{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import backend as K\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sklearn.metrics as metrics \n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes\n",
    "- Modifying the batch size. \n",
    "- Batch size is the total number pf trainign examples present in a single bacth. \n",
    "- The epoch is whedn the entire dataset is passed forward and backward through the neural netowrk only once. \n",
    "- Started with epoch 8 and batch size to 128 in first set of trials. \n",
    "- See what happens when the batch size is decreased but epoch size is the same. \n",
    "- Will test to see what happends when epoch is increased to see robostness of each model. \n",
    "# Testing the following of each model\n",
    "- Run time \n",
    "- Model perforamce \n",
    "- Modifications in epoch and batch sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44938 images belonging to 2 classes.\n",
      "Found 5616 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = '/home/mlab/Documents/brats_hl_data/train'\n",
    "validation_data_dir = '/home/mlab/Documents/brats_hl_data/val'\n",
    "# 44938\n",
    "# 5616\n",
    "nb_train_samples = 44938\n",
    "nb_validation_samples = 5616\n",
    "epochs = 8\n",
    "batch_size = 32\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0216 12:59:20.907174 139821710448448 deprecation_wrapper.py:119] From /home/mlab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0216 12:59:20.919327 139821710448448 deprecation_wrapper.py:119] From /home/mlab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0216 12:59:20.922879 139821710448448 deprecation_wrapper.py:119] From /home/mlab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0216 12:59:20.933403 139821710448448 deprecation_wrapper.py:119] From /home/mlab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0216 12:59:20.968142 139821710448448 deprecation_wrapper.py:119] From /home/mlab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0216 12:59:20.972705 139821710448448 deprecation.py:506] From /home/mlab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#uses a smal vggnet\n",
    "#32->64->128->512\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(512,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid')) #uses sigmoid at the end because we onlu have two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 512)       590336    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,529,665\n",
      "Trainable params: 13,529,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0216 12:59:21.021493 139821710448448 deprecation_wrapper.py:119] From /home/mlab/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0216 12:59:21.026103 139821710448448 deprecation_wrapper.py:119] From /home/mlab/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0216 12:59:21.029068 139821710448448 deprecation.py:323] From /home/mlab/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#We use the RMSprop optimizer with a learning rate of 0.0001\n",
    "#We use ninary_crossentropy loss because its a binary classification\n",
    "#optimizer = Adam(learning_rate=lr_schedule(0))\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.Adam(lr=1e-4),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "['high', 'low']\n"
     ]
    }
   ],
   "source": [
    "true_classes = train_generator.classes\n",
    "print(true_classes)\n",
    "class_labels = list(train_generator.class_indices.keys())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "1404/1404 [==============================] - 675s 481ms/step - loss: 0.5941 - acc: 0.6645 - val_loss: 0.5772 - val_acc: 0.6932\n",
      "Epoch 2/8\n",
      "1194/1404 [========================>.....] - ETA: 1:39 - loss: 0.5147 - acc: 0.7292"
     ]
    }
   ],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "history =model.fit_generator(train_generator,\n",
    "                             steps_per_epoch=nb_train_samples//batch_size,\n",
    "                             epochs=epochs,\n",
    "                             validation_data=validation_generator,\n",
    "                             validation_steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #save the model\n",
    "# model.save_weights('model_weights.h5')\n",
    "# model.save('model_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.argmax(Y_pred, axis=1)\n",
    "y_pred = (Y_pred<0.475).astype(np.int)\n",
    "\n",
    "# print('Confusion Matrix')\n",
    "# print(confusion_matrix(true_classes_1, y_pred))\n",
    "# print('Classification Report')\n",
    "# print(classification_report(validation_generator.classes, y_pred, \n",
    "#                             target_names=class_labels_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes_1 = validation_generator.classes\n",
    "print(true_classes)\n",
    "class_labels_1 = list(validation_generator.class_indices.keys())\n",
    "print(class_labels_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(true_classes_1,y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report= sklearn.metrics.classification_report(true_classes_1, y_pred, \n",
    "                                              target_names = class_labels_1)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(validation_generator.classes, y_pred)\n",
    "\n",
    "# create plot\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random guess')\n",
    "_ = plt.xlabel('False Positive Rate')\n",
    "_ = plt.ylabel('True Positive Rate')\n",
    "_ = plt.title('ROC Curve')\n",
    "_ = plt.xlim([-0.02, 1])\n",
    "_ = plt.ylim([0, 1.02])\n",
    "_ = plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(validation_generator.classes, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchX, batchy = train_generator.next()\n",
    "_, accuracy = model.evaluate(batchX, batchy)\n",
    "print('Accuracy training: %.2f' % (accuracy*100))\n",
    "batchXv, batchyv = validation_generator.next()\n",
    "_, accuracy = model.evaluate(batchXv, batchyv)\n",
    "print('Accuracy val: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the train and val curve\n",
    "#get the details from the history object\n",
    "acc = history.history['acc']\n",
    "val_acc=history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1,len(acc)+1)\n",
    "\n",
    "#train and validation accuracy\n",
    "plt.plot(epochs,acc,'b',label='Training accuracy')\n",
    "plt.plot(epochs,val_acc,'r',label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and validation loss\n",
    "plt.plot(epochs, loss, 'b',label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r',label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_datagen.flow_from_directory('/home/mlab/Documents/brats_hl_data/test', \n",
    "                                      class_mode='binary', \n",
    "                                      batch_size=batch_size, \n",
    "                                      target_size=(150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate_generator(test_generator, steps=nb_validation_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confution Matrix and Classification Report\n",
    "# Y_pred = model.predict_generator(val_generator, 5616 // batch_size)\n",
    "nb_test_samples=5619\n",
    "Y_pred1 = model.predict_generator(test_generator,nb_test_samples//batch_size+1)\n",
    "# y_pred = np.argmax(Y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_classes_2 = test_generator.classes\n",
    "print(true_classes_2)\n",
    "class_labels_2 = list(test_generator.class_indices.keys())\n",
    "print(class_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred1 = (Y_pred1<0.5).astype(np.int)\n",
    "y_pred1 = (Y_pred1 < 0.475).astype(np.int)\n",
    "# print(y_pred)\n",
    "# print('Confusion Matrix')\n",
    "# print(confusion_matrix(true_classes_2, y_pred1))\n",
    "# print('Classification Report')\n",
    "# print(classification_report(true_classes_2, y_pred1, target_names=class_labels_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix1 = metrics.confusion_matrix(true_classes_2,y_pred1)\n",
    "print(confusion_matrix1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report1= sklearn.metrics.classification_report(true_classes_2, y_pred1, \n",
    "                                               target_names = class_labels_2)\n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Loss: \", scores[0],\"\\n\",\"Accuracy: \", scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
